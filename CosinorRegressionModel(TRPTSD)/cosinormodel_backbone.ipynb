{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a8cbf6",
   "metadata": {},
   "source": [
    "## Cosinor Regression Model for \"Episode Analysis\"\n",
    "This is the Cosinor Regression model used for the new sample datasets that contain the daily episode of TR-PTSD symptoms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca56713",
   "metadata": {},
   "source": [
    "### SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.ma import add\n",
    "\n",
    "from CosinorPy import file_parser, cosinor, cosinor1\n",
    "np.seterr(divide='ignore')\n",
    "import scipy.signal as signal\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.multitest as multi\n",
    "from scipy.optimize import curve_fit\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from scipy.stats import percentileofscore\n",
    "from scipy.stats import circstd, circmean\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "from matplotlib.lines import Line2D\n",
    "from random import sample\n",
    "\n",
    "import os\n",
    "\n",
    "import copy\n",
    "\n",
    "from CosinorPy.helpers import df_add_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c0024",
   "metadata": {},
   "source": [
    "### Data Cleaning for Cosinor Model Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"Function used to parser the data using the file_parser method from the CosinorPy package\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df['Region start time'] = pd.to_datetime(df['Region start time'])\n",
    "    df['date'] = df['Region start time'].dt.date\n",
    "    df['hour'] = df['Region start time'].dt.hour\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "def to_matrix(df, event_col, min_valid_hours = 12):\n",
    "    # Pivot to days x hours\n",
    "    matrix = df.pivot(index='date', columns='hour', values=event_col)\n",
    "    matrix = matrix.interpolate(axis=1, limit_direction='both')\n",
    "    matrix = matrix[matrix.count(axis=1) >= min_valid_hours]\n",
    "    matrix = matrix.fillna(0)\n",
    "    print(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = load_data(\"data/RNS_G_Pre_output.csv\")\n",
    "post_data = load_data(\"data/RNS_G_M1_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f8be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_matrix = to_matrix(pre_data, \"Pattern A Channel 2\")\n",
    "post_matrix = to_matrix(post_data, \"Pattern A Channel 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935e8a8",
   "metadata": {},
   "source": [
    "## Cosinor Model Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afe33a3",
   "metadata": {},
   "source": [
    "### Cosinor Model Analysis - Overview Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824726d",
   "metadata": {},
   "source": [
    "This setting has the following features:   \n",
    "    1. Date and time was combined using the format of decimals: specific hours were converted into decimal places of the given days\n",
    "    2. The combined timeline is the x-axis and the test data (Pattern A Channel 2 or Episode starts with RX) is the y-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5800d33f",
   "metadata": {},
   "source": [
    "#### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ec281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosinor_regression1(df):\n",
    "    \"\"\"Basic Cosinor Regression Model used for the episode data (Pattern A Channel 2), normalizing time into a consecutive arithmetic timestamp.\"\"\"\n",
    "    df1 = df.copy()\n",
    "    df1[\"test\"] = df1[\"Pattern A Channel 2\"]\n",
    "    df1[\"x\"] = df1[\"Region start time\"]  # use this datetime field\n",
    "    df1[\"y\"] = df1[\"date\"]\n",
    "\n",
    "    # Convert Region start time to fractional days since first timepoint\n",
    "    df1[\"x\"] = pd.to_datetime(df1[\"x\"])  # ensure proper datetime format\n",
    "    t0 = df1[\"x\"].min()\n",
    "    df1[\"x\"] = df1[\"x\"].apply(lambda t: (t - t0).total_seconds() / (24 * 3600))  # days as float\n",
    "\n",
    "    # Optional: Convert y to numeric if needed\n",
    "    df1[\"y\"] = df1[\"y\"].apply(lambda x: x.toordinal() if hasattr(x, \"toordinal\") else x)\n",
    "\n",
    "    df1 = df1.drop([\"Region start time\", \"Pattern A Channel 2\", \"Episode starts with RX\", \"date\", \"hour\"], axis=1)\n",
    "    print(df1)\n",
    "\n",
    "    cosinor.fit_me(df1[\"x\"], df1[\"test\"])\n",
    "\n",
    "def cosinor_regression2(df):\n",
    "    \"\"\"Basic Cosinor Regression Model used for the episode data (Episode starts with RX), normalizing time into a consecutive arithmetic timestamp.\"\"\"\n",
    "    df1 = df.copy()\n",
    "    df1[\"test\"] = df1[\"Episode starts with RX\"]\n",
    "    df1[\"x\"] = df1[\"Region start time\"]  # use this datetime field\n",
    "    df1[\"y\"] = df1[\"date\"]\n",
    "\n",
    "    # Convert Region start time to fractional days since first timepoint\n",
    "    df1[\"x\"] = pd.to_datetime(df1[\"x\"])  # ensure proper datetime format\n",
    "    t0 = df1[\"x\"].min()\n",
    "    df1[\"x\"] = df1[\"x\"].apply(lambda t: (t - t0).total_seconds() / (24 * 3600))  # days as float\n",
    "\n",
    "    # Optional: Convert y to numeric if needed\n",
    "    df1[\"y\"] = df1[\"y\"].apply(lambda x: x.toordinal() if hasattr(x, \"toordinal\") else x)\n",
    "\n",
    "    df1 = df1.drop([\"Region start time\", \"Pattern A Channel 2\", \"Episode starts with RX\", \"date\", \"hour\"], axis=1)\n",
    "    print(df1)\n",
    "\n",
    "    cosinor.fit_me(df1[\"x\"], df1[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33940ede",
   "metadata": {},
   "source": [
    "#### Pre_data Analysis (Before Stimulus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bdaec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosinor_regression1(pre_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef772e",
   "metadata": {},
   "source": [
    "#### Post_data Analysis (After Stimulus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3031170",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosinor_regression1(post_data)\n",
    "cosinor_regression2(post_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f916405",
   "metadata": {},
   "source": [
    "#### Overall Analysis merging two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259332f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosinor_both(df1, df2):\n",
    "    \"\"\"Concatenate two dataframes and fit a Cosinor regression model.\"\"\"\n",
    "    # df1 dataset cleaning and preparation\n",
    "    df1_copy = df1.copy()\n",
    "    df1_copy[\"test\"] = df1_copy[\"Pattern A Channel 2\"]\n",
    "    df1_copy[\"x\"] = df1_copy[\"Region start time\"]  # use this datetime field\n",
    "    df1_copy[\"y\"] = df1_copy[\"date\"]\n",
    "\n",
    "    # Convert Region start time to fractional days since first timepoint\n",
    "    df1_copy[\"x\"] = pd.to_datetime(df1_copy[\"x\"])  # ensure proper datetime format\n",
    "    t0 = df1_copy[\"x\"].min()\n",
    "    df1_copy[\"x\"] = df1_copy[\"x\"].apply(lambda t: (t - t0).total_seconds() / (24 * 3600))  # days as float\n",
    "    df1_copy[\"y\"] = df1_copy[\"y\"].apply(lambda x: x.toordinal() if hasattr(x, \"toordinal\") else x)\n",
    "\n",
    "    df1_copy = df1_copy.drop([\"Pattern A Channel 2\", \"Episode starts with RX\", \"date\", \"hour\"], axis=1)\n",
    "    \n",
    "    x_shift = df1_copy[\"x\"].max()\n",
    "\n",
    "    # df2 dataset cleaning and preparation\n",
    "    df2_copy = df2.copy()\n",
    "    df2_copy[\"test\"] = df2_copy[\"Pattern A Channel 2\"]\n",
    "    df2_copy[\"x\"] = df2_copy[\"Region start time\"]  # use this datetime field\n",
    "    df2_copy[\"y\"] = df2_copy[\"date\"]\n",
    "\n",
    "    # Convert Region start time to fractional days since first timepoint\n",
    "    df2_copy[\"x\"] = pd.to_datetime(df2_copy[\"x\"])  # ensure proper datetime format\n",
    "    t0 = df2_copy[\"x\"].min()\n",
    "    df2_copy[\"x\"] = df2_copy[\"x\"].apply(lambda t: (t - t0).total_seconds() / (24 * 3600))  # days as float\n",
    "    df2_copy[\"y\"] = df2_copy[\"y\"].apply(lambda x: x.toordinal() if hasattr(x, \"toordinal\") else x)\n",
    "\n",
    "    df2_copy = df2_copy.drop([\"Pattern A Channel 2\", \"Episode starts with RX\", \"date\", \"hour\"], axis=1)\n",
    "\n",
    "    df2_copy[\"x\"] += x_shift  # shift x-axis to be consecutive\n",
    "    # Step 2: Concatenate\n",
    "    df_full = pd.concat([df1_copy, df2_copy], ignore_index=True)\n",
    "    # Step 3: Plot or fit\n",
    "    cosinor.fit_me(df_full[\"x\"], df_full[\"test\"])\n",
    "\n",
    "cosinor_both(pre_data, post_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e0baf",
   "metadata": {},
   "source": [
    "### Cosinor Model Analysis - Specific Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f03f9c",
   "metadata": {},
   "source": [
    "This setting has the following features:    \n",
    "    1. x-axis and y-axis are date and hour respectively    \n",
    "    2. Data points lower than a specific \"threshold\" are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosinor_regression_specific1(df1, df2):\n",
    "    \"\"\"\n",
    "    The specfic Cosinor Regression Model used for the episode data (Pattern A Channel 2), normalizing time into a consecutive arithmetic timestamp.\n",
    "    This function is similar to cosinor_regression1 but uses a specific standard to reduce the \"noise\" of the dataset.\n",
    "    \"\"\"\n",
    "    df1_copy = df1.copy()\n",
    "    # Filtering\n",
    "    df1_clean = df1_copy[df1_copy[\"Pattern A Channel 2\"] < 20]\n",
    "    df1_clean = df1_clean[df1_clean[\"Pattern A Channel 2\"] != 255]\n",
    "\n",
    "\n",
    "    # Clean and prepare df1\n",
    "    df1_clean[\"test\"] = df1_clean[\"Pattern A Channel 2\"]\n",
    "    df1_clean[\"x\"] = df1_clean[\"date\"]  # use this datetime field\n",
    "    df1_clean[\"y\"] = df1_clean[\"hour\"]\n",
    "\n",
    "    # Convert Region start time to fractional days since first timepoint\n",
    "    df1_clean[\"x\"] = pd.to_datetime(df1_clean[\"x\"])  # ensure proper datetime format\n",
    "    t0 = df1_clean[\"x\"].min()\n",
    "    df1_clean[\"x\"] = df1_clean[\"x\"].apply(lambda t: (t - t0).total_seconds() / (24 * 3600))  # days as float\n",
    "    df1_clean[\"y\"] = df1_clean[\"y\"].apply(lambda x: x.toordinal() if hasattr(x, \"toordinal\") else x)\n",
    "\n",
    "    df1_clean = df1_clean.drop([\"Pattern A Channel 2\", \"Episode starts with RX\", \"date\", \"hour\"], axis=1)\n",
    "    print(df1_clean)\n",
    "\n",
    "    x_shift = df1_clean[\"x\"].max()\n",
    "    \n",
    "    df2_copy = df2.copy()\n",
    "    # Filtering\n",
    "    df2_clean = df2_copy[df2_copy[\"Pattern A Channel 2\"] < 20] \n",
    "    df2_clean = df2_clean[df2_clean[\"Pattern A Channel 2\"] != 255]\n",
    "\n",
    "    # Clean and prepare df2\n",
    "    df2_clean[\"test\"] = df2_clean[\"Pattern A Channel 2\"]\n",
    "    df2_clean[\"x\"] = df2_clean[\"date\"]  # use this datetime field\n",
    "    df2_clean[\"y\"] = df2_clean[\"hour\"]\n",
    "    \n",
    "    df2_clean[\"x\"] = pd.to_datetime(df2_clean[\"x\"])  # ensure proper datetime format\n",
    "    t0 = df2_clean[\"x\"].min()\n",
    "    df2_clean[\"x\"] = df2_clean[\"x\"].apply(lambda t: (t - t0).total_seconds() / (24 * 3600))  # days as float\n",
    "    df2_clean[\"y\"] = df2_clean[\"y\"].apply(lambda x: x.toordinal() if hasattr(x, \"toordinal\") else x)\n",
    "\n",
    "    df2_clean = df2_clean.drop([\"Pattern A Channel 2\", \"Episode starts with RX\", \"date\", \"hour\"], axis=1)\n",
    "\n",
    "    # Final combination\n",
    "    df2_clean[\"x\"] += x_shift  # shift x-axis to be consecutive for plotting\n",
    "    df_full = pd.concat([df1_clean, df2_clean], ignore_index=True)\n",
    "    \n",
    "\n",
    "    cosinor.fit_me(df_full[\"x\"], df_full[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f44f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosinor_regression_specific1(pre_data, post_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4db6876",
   "metadata": {},
   "source": [
    "### Counting Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd44fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosinor_count_both_patternA(df1, df2):\n",
    "    \"\"\"Concatenate two dataframes and fit a Cosinor regression model for everyday count of the episodes.\"\"\"\n",
    "    df1_copy = df1.copy()\n",
    "    df2_copy = df2.copy()\n",
    "\n",
    "    # Combine the two dataframes\n",
    "    df_combined = pd.concat([df1_copy, df2_copy], ignore_index=True)\n",
    "\n",
    "    # Ensure datetime format\n",
    "    df_combined['date'] = pd.to_datetime(df_combined['date'])\n",
    "\n",
    "    # Extract date (without time) and assign it back\n",
    "    df_combined['day'] = df_combined['date'].dt.date\n",
    "\n",
    "    # Group by day and count non-zero \"Pattern A Channel 2\" values\n",
    "    grouped = df_combined.groupby('day')[\"Pattern A Channel 2\"].apply(lambda x: (x != 0).sum()).reset_index()\n",
    "\n",
    "    # Rename columns\n",
    "    grouped.columns = ['day', 'non_zero_count']\n",
    "\n",
    "    # Convert day to consecutive integers starting from 0\n",
    "    grouped['x'] = (pd.to_datetime(grouped['day']) - pd.to_datetime(grouped['day']).min()).dt.days\n",
    "\n",
    "    cosinor.fit_me(grouped[\"x\"], grouped[\"non_zero_count\"])\n",
    "\n",
    "cosinor_count_both_patternA(pre_data, post_data)\n",
    "\n",
    "def cosinor_count_both_EpisodeRX(df1, df2):\n",
    "    \"\"\"Concatenate two dataframes and fit a Cosinor regression model for everyday count of the episodes.\"\"\"\n",
    "    df1_copy = df1.copy()\n",
    "    df2_copy = df2.copy()\n",
    "\n",
    "    # Combine the two dataframes\n",
    "    df_combined = pd.concat([df1_copy, df2_copy], ignore_index=True)\n",
    "\n",
    "    # Ensure datetime format\n",
    "    df_combined['date'] = pd.to_datetime(df_combined['date'])\n",
    "\n",
    "    # Extract date (without time) and assign it back\n",
    "    df_combined['day'] = df_combined['date'].dt.date\n",
    "\n",
    "    # Group by day and count non-zero \"Pattern A Channel 2\" values\n",
    "    grouped = df_combined.groupby('day')[\"Episode starts with RX\"].apply(lambda x: (x != 0).sum()).reset_index()\n",
    "\n",
    "    # Rename columns\n",
    "    grouped.columns = ['day', 'non_zero_count']\n",
    "\n",
    "    # Convert day to consecutive integers starting from 0\n",
    "    grouped['x'] = (pd.to_datetime(grouped['day']) - pd.to_datetime(grouped['day']).min()).dt.days\n",
    "\n",
    "    cosinor.fit_me(grouped[\"x\"], grouped[\"non_zero_count\"])\n",
    "\n",
    "cosinor_count_both_EpisodeRX(pre_data, post_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e31033",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4802beea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7190e2ac",
   "metadata": {},
   "source": [
    "### Plots and Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
